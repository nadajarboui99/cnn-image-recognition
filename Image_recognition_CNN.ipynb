{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP_3 Les Réseaux de Neurones Convolutifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif:\n",
    "Dans ce TP, on va essayer de résoudre un probléme de reconnaissance d'images en utilisant les CNNS. On va utiliser 3 architectures differentes, les évaluer, et deduire la meilleure architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset\n",
    "On va charger les données, 60 000 images d'apprentissages  et 10 000 images de test en niveaux de gris.\n",
    "Les images sont des matrices carrées de taille 28x28 et sont que des chiffres uniques entre  et 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape data\n",
    "Les images MNIST sont fournies en format (60000, 28, 28) pour les données d'entraînement, et (10000, 28, 28) pour celles de test.\n",
    "Il manque une dimension pour les \"canaux\" (channels), qui est indispensable pour les CNNs.\n",
    "Un CNN attend des entrées en format 4D :\n",
    "[nombre d'images, largeur, hauteur, nombre de canaux]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding\n",
    "Un CNN ne peut pas prédire directement des entiers. Il prévoit un vecteur de probabilités pour chaque classe.\n",
    "On va utilisé le One-Hot Encoding pour convertir chaque chiffre (0 à 9) en un vecteur de taille 10 où un seul élément est 1, et le reste sont des 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_mnist():\n",
    "    # Load dataset\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Reshape to be [samples][width][height][pixels] = (batch, 28, 28, 1)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "    # One hot encode outputs\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    num_classes = y_test.shape[1]\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test), num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small CNN \n",
    "Ce modèle CNN simple est composé de deux couches de convolution (3x3), suivies d’un flatten et d’une sortie softmax.\n",
    "Il sert de base pour observer le comportement d’un réseau de neurones convolutifs minimaliste sur MNIST.\n",
    "Il permet déjà d’obtenir de bons résultats pour des tâches simples de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "def small_model(num_classes):\n",
    "    # create model\n",
    "    model = Sequential()  #Pour déclarer un nouveau modèle de deep learning\n",
    "    model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu'))  #convolution de 64 filtres en 3×3 suivie d’une couche d’activation ReLU\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))  #convolution de 32 filtres en 3×3 suivie d’une couche d’activation ReLU\n",
    "    model.add(Flatten()) #création du vecteur final à envoyer au réseau de neurones artificiels\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compiler le modèle\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 26s - 86ms/step - accuracy: 0.9246 - loss: 0.8608 - val_accuracy: 0.9731 - val_loss: 0.0874\n",
      "Epoch 2/10\n",
      "300/300 - 21s - 71ms/step - accuracy: 0.9808 - loss: 0.0642 - val_accuracy: 0.9764 - val_loss: 0.0793\n",
      "Epoch 3/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9860 - loss: 0.0436 - val_accuracy: 0.9788 - val_loss: 0.0782\n",
      "Epoch 4/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9905 - loss: 0.0290 - val_accuracy: 0.9795 - val_loss: 0.0814\n",
      "Epoch 5/10\n",
      "300/300 - 21s - 69ms/step - accuracy: 0.9925 - loss: 0.0229 - val_accuracy: 0.9769 - val_loss: 0.0954\n",
      "Epoch 6/10\n",
      "300/300 - 21s - 71ms/step - accuracy: 0.9929 - loss: 0.0224 - val_accuracy: 0.9756 - val_loss: 0.0989\n",
      "Epoch 7/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9944 - loss: 0.0167 - val_accuracy: 0.9779 - val_loss: 0.0974\n",
      "Epoch 8/10\n",
      "300/300 - 21s - 69ms/step - accuracy: 0.9955 - loss: 0.0132 - val_accuracy: 0.9775 - val_loss: 0.1215\n",
      "Epoch 9/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9952 - loss: 0.0145 - val_accuracy: 0.9772 - val_loss: 0.1054\n",
      "Epoch 10/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9953 - loss: 0.0142 - val_accuracy: 0.9769 - val_loss: 0.1441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2362b678140>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=10\n",
    "(X_train, y_train), (X_test, y_test), num_classes = get_data_mnist()\n",
    "model = small_model(num_classes)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle atteint rapidement une bonne précision, avec 99,5 % sur les données d'entraînement à la 10ᵉ époque.\n",
    "\n",
    "Cependant, la perte de validation augmente après quelques époques, ce qui indique un début d'overfitting (le modèle mémorise au lieu de généraliser).\n",
    "\n",
    "Le val_loss monte jusqu’à 0.142, ce qui est relativement élevé comparé au début de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 97.69%\n",
      "Model error rate : 2.31%\n"
     ]
    }
   ],
   "source": [
    "def print_model_error_rate(model, X_test, y_test):\n",
    "    # Évaluation finale du modèle\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"Model score : %.2f%%\" % (scores[1] * 100))\n",
    "    print(\"Model error rate : %.2f%%\" % (100 - scores[1] * 100))\n",
    "print_model_error_rate(model, X_test, y_test)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score final sur les données de test est 97,69 %, ce qui reste très bon.\n",
    "\n",
    "Le taux d’erreur est de 2,31 %, mais il aurait pu être meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données Normalisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_mnist_normalized():\n",
    "    # Load dataset\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Reshape to be [samples][width][height][pixels] = (batch, 28, 28, 1)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "    # Normalize pixel values to [0,1]\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0\n",
    "\n",
    "    # One hot encode outputs\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    num_classes = y_test.shape[1]\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test), num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du small CNN aprés normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 22s - 73ms/step - accuracy: 0.9391 - loss: 0.2255 - val_accuracy: 0.9771 - val_loss: 0.0715\n",
      "Epoch 2/10\n",
      "300/300 - 21s - 69ms/step - accuracy: 0.9819 - loss: 0.0625 - val_accuracy: 0.9835 - val_loss: 0.0530\n",
      "Epoch 3/10\n",
      "300/300 - 23s - 76ms/step - accuracy: 0.9866 - loss: 0.0438 - val_accuracy: 0.9840 - val_loss: 0.0478\n",
      "Epoch 4/10\n",
      "300/300 - 22s - 74ms/step - accuracy: 0.9893 - loss: 0.0346 - val_accuracy: 0.9856 - val_loss: 0.0488\n",
      "Epoch 5/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9918 - loss: 0.0261 - val_accuracy: 0.9853 - val_loss: 0.0476\n",
      "Epoch 6/10\n",
      "300/300 - 21s - 71ms/step - accuracy: 0.9937 - loss: 0.0196 - val_accuracy: 0.9867 - val_loss: 0.0468\n",
      "Epoch 7/10\n",
      "300/300 - 21s - 71ms/step - accuracy: 0.9953 - loss: 0.0160 - val_accuracy: 0.9863 - val_loss: 0.0489\n",
      "Epoch 8/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9962 - loss: 0.0124 - val_accuracy: 0.9856 - val_loss: 0.0509\n",
      "Epoch 9/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.9854 - val_loss: 0.0553\n",
      "Epoch 10/10\n",
      "300/300 - 21s - 70ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9869 - val_loss: 0.0570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23626e9a180>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_normalized, y_train_normalized), (X_test_normalized, y_test_normalized), num_classes = get_data_mnist_normalized()\n",
    "model_normalized = small_model(num_classes)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model_normalized.fit(X_train_normalized, y_train_normalized, validation_data=(X_test_normalized, y_test_normalized), epochs=10, batch_size=200, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle démarre avec une perte plus faible 0.2255 contre 0.8608 dès la première époque.\n",
    "\n",
    "La val_loss reste stable et basse tout au long de l'entraînement, preuve que le modèle généralise mieux.\n",
    "\n",
    "Pas de signe d’overfitting apparent après 10 époques.\n",
    "\n",
    "Le modèle apprend plus efficacement et converge plus vite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 98.69%\n",
      "Model error rate : 1.31%\n"
     ]
    }
   ],
   "source": [
    "print_model_error_rate(model_normalized, X_test_normalized, y_test_normalized)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score final atteint 98,69 %, soit 1,31 % de taux d’erreur, ce qui est nettement meilleur que sans normalisation.\n",
    "\n",
    "Cela confirme que la normalisation améliore la précision, la stabilité et la capacité du modèle à bien se comporter sur de nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meduim CNN\n",
    "\n",
    "Ce modèle CNN de complexité moyenne comprend une couche de convolution 5x5 suivie d'un max-pooling, puis un dropout pour éviter l’overfitting. Il se termine par un dense à 128 neurones puis un softmax pour la classification.\n",
    "Il est plus puissant que le modèle Small CNN et constitue une bonne base pour des performances solides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "def medium_model(input_shape=(28, 28, 1), num_classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Medium CNN model...\n",
      "Epoch 1/10\n",
      "270/270 - 6s - 22ms/step - accuracy: 0.9264 - loss: 0.2571 - val_accuracy: 0.9798 - val_loss: 0.0763\n",
      "Epoch 2/10\n",
      "270/270 - 5s - 19ms/step - accuracy: 0.9767 - loss: 0.0780 - val_accuracy: 0.9867 - val_loss: 0.0503\n",
      "Epoch 3/10\n",
      "270/270 - 5s - 18ms/step - accuracy: 0.9832 - loss: 0.0549 - val_accuracy: 0.9885 - val_loss: 0.0420\n",
      "Epoch 4/10\n",
      "270/270 - 5s - 18ms/step - accuracy: 0.9864 - loss: 0.0435 - val_accuracy: 0.9875 - val_loss: 0.0445\n",
      "Epoch 5/10\n",
      "270/270 - 5s - 19ms/step - accuracy: 0.9889 - loss: 0.0351 - val_accuracy: 0.9902 - val_loss: 0.0373\n",
      "Epoch 6/10\n",
      "270/270 - 5s - 19ms/step - accuracy: 0.9903 - loss: 0.0294 - val_accuracy: 0.9877 - val_loss: 0.0425\n",
      "Epoch 7/10\n",
      "270/270 - 5s - 18ms/step - accuracy: 0.9919 - loss: 0.0247 - val_accuracy: 0.9888 - val_loss: 0.0436\n",
      "Epoch 8/10\n",
      "270/270 - 5s - 19ms/step - accuracy: 0.9927 - loss: 0.0221 - val_accuracy: 0.9878 - val_loss: 0.0409\n",
      "Epoch 9/10\n",
      "270/270 - 5s - 20ms/step - accuracy: 0.9948 - loss: 0.0174 - val_accuracy: 0.9895 - val_loss: 0.0368\n",
      "Epoch 10/10\n",
      "270/270 - 5s - 19ms/step - accuracy: 0.9949 - loss: 0.0154 - val_accuracy: 0.9885 - val_loss: 0.0441\n",
      "\n",
      "Medium CNN - Model score : 98.95%\n",
      "Medium CNN - Model error rate : 1.05%\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données normalisées\n",
    "(X_train, y_train), (X_test, y_test), num_classes = get_data_mnist_normalized()\n",
    "\n",
    "# Création du modèle Medium\n",
    "model_medium = medium_model(input_shape=(28, 28, 1), num_classes=num_classes)\n",
    "\n",
    "# Entraînement\n",
    "print(\"Training Medium CNN model...\")\n",
    "history_medium = model_medium.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Évaluation\n",
    "score_medium = model_medium.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nMedium CNN - Model score : {score_medium[1] * 100:.2f}%\")\n",
    "print(f\"Medium CNN - Model error rate : {(1 - score_medium[1]) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle Medium CNN a montré une très bonne performance avec une précision finale de 98.95 %. La courbe d'entraînement est stable et les pertes diminuent progressivement, indiquant une bonne convergence. Ce modèle reste simple mais efficace pour la classification MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large CNN\n",
    "\n",
    "Ce modèle CNN plus complexe enchaîne deux convolutions (5x5 puis 3x3) avec max-pooling et dropout, puis passe par deux couches fully connected (128 et 50 neurones). \n",
    "Il est conçu pour extraire des motifs plus fins et mieux généraliser grâce à une architecture plus profonde. Il convient mieux aux environnements où l'on cherche une très haute précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_model(input_shape=(28, 28, 1), num_classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Large CNN model...\n",
      "Epoch 1/10\n",
      "270/270 - 6s - 21ms/step - accuracy: 0.9075 - loss: 0.3150 - val_accuracy: 0.9790 - val_loss: 0.0806\n",
      "Epoch 2/10\n",
      "270/270 - 4s - 16ms/step - accuracy: 0.9740 - loss: 0.0864 - val_accuracy: 0.9862 - val_loss: 0.0533\n",
      "Epoch 3/10\n",
      "270/270 - 4s - 16ms/step - accuracy: 0.9824 - loss: 0.0572 - val_accuracy: 0.9892 - val_loss: 0.0446\n",
      "Epoch 4/10\n",
      "270/270 - 4s - 15ms/step - accuracy: 0.9858 - loss: 0.0460 - val_accuracy: 0.9888 - val_loss: 0.0413\n",
      "Epoch 5/10\n",
      "270/270 - 5s - 18ms/step - accuracy: 0.9891 - loss: 0.0353 - val_accuracy: 0.9905 - val_loss: 0.0365\n",
      "Epoch 6/10\n",
      "270/270 - 5s - 18ms/step - accuracy: 0.9897 - loss: 0.0318 - val_accuracy: 0.9898 - val_loss: 0.0393\n",
      "Epoch 7/10\n",
      "270/270 - 4s - 16ms/step - accuracy: 0.9919 - loss: 0.0258 - val_accuracy: 0.9890 - val_loss: 0.0423\n",
      "Epoch 8/10\n",
      "270/270 - 4s - 16ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9903 - val_loss: 0.0393\n",
      "Epoch 9/10\n",
      "270/270 - 5s - 18ms/step - accuracy: 0.9937 - loss: 0.0195 - val_accuracy: 0.9918 - val_loss: 0.0336\n",
      "Epoch 10/10\n",
      "270/270 - 4s - 16ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 0.9907 - val_loss: 0.0394\n",
      "\n",
      "Large CNN - Model score : 99.33%\n",
      "Large CNN - Model error rate : 0.67%\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle Large\n",
    "model_large = large_model(input_shape=(28, 28, 1), num_classes=num_classes)\n",
    "\n",
    "# Entraînement\n",
    "print(\"Training Large CNN model...\")\n",
    "history_large = model_large.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Évaluation\n",
    "score_large = model_large.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nLarge CNN - Model score : {score_large[1] * 100:.2f}%\")\n",
    "print(f\"Large CNN - Model error rate : {(1 - score_large[1]) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle Large CNN a obtenu une précision encore plus élevée de 99.33% avec un taux d'erreur 0.67% plus faible, confirmant l’avantage d’une architecture plus profonde. Il montre une excellente capacité de généralisation avec une perte de validation qui reste faible et stable. Ce modèle est bien adapté aux tâches demandant une meilleure extraction de caractéristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keras_model(model, filename):\n",
    "    model_json = model.to_json()\n",
    "    with open(filename + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(filename + \".weights.h5\")  # Nom corrigé\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde des 3 modéles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des trois modèles entraînés\n",
    "save_keras_model(model_normalized, \"small_cnn_model\")\n",
    "save_keras_model(model_medium, \"medium_cnn_model\")\n",
    "save_keras_model(model_large, \"large_cnn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keras_model(filename):\n",
    "    with open(filename + \".json\", \"r\") as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(filename + \".weights.h5\")  # CORRECTION ICI\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des 3 modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des trois modèles\n",
    "model_small_loaded = load_keras_model(\"small_cnn_model\")\n",
    "model_medium_loaded = load_keras_model(\"medium_cnn_model\")\n",
    "model_large_loaded = load_keras_model(\"large_cnn_model\")\n",
    "\n",
    "# on doit compiler les modèles avant de les utiliser\n",
    "for model in [model_small_loaded, model_medium_loaded, model_large_loaded]:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va évaluer les 3 modèles aprés le chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small CNN (chargé) - Précision : 98.69% | Erreur : 1.31%\n",
      "Medium CNN (chargé) - Précision : 98.95% | Erreur : 1.05%\n",
      "Large CNN (chargé) - Précision : 99.33% | Erreur : 0.67%\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "(_, _), (X_test, y_test), _ = get_data_mnist_normalized()\n",
    "\n",
    "# Évaluation du modèle small\n",
    "score_small = model_small_loaded.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Small CNN (chargé) - Précision : {score_small[1]*100:.2f}% | Erreur : {(1 - score_small[1])*100:.2f}%\")\n",
    "\n",
    "# Évaluation du modèle medium\n",
    "score_medium = model_medium_loaded.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Medium CNN (chargé) - Précision : {score_medium[1]*100:.2f}% | Erreur : {(1 - score_medium[1])*100:.2f}%\")\n",
    "\n",
    "# Évaluation du modèle large\n",
    "score_large = model_large_loaded.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Large CNN (chargé) - Précision : {score_large[1]*100:.2f}% | Erreur : {(1 - score_large[1])*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va tester les 3 modèles sur un exemple concret pour vérifier que la sauvegarde et le chargement fonctionnent correctement et que nos modèles sont prêtes à être utilisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choisir une image de test aléatoire\n",
    "index = np.random.randint(0, X_test.shape[0])\n",
    "image = X_test[index]\n",
    "true_label = np.argmax(y_test[index])\n",
    "\n",
    "# Fonction pour prédire avec un modèle donné\n",
    "def get_prediction_info(model, image):\n",
    "    prediction = model.predict(image.reshape(1, 28, 28, 1), verbose=0)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    confidence = np.max(prediction) * 100\n",
    "    return predicted_label, confidence\n",
    "\n",
    "# Obtenir les prédictions\n",
    "pred_small, conf_small = get_prediction_info(model_small_loaded, image)\n",
    "pred_medium, conf_medium = get_prediction_info(model_medium_loaded, image)\n",
    "pred_large, conf_large = get_prediction_info(model_large_loaded, image)\n",
    "\n",
    "# Affichage côte à côte\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "models = [\"Small CNN\", \"Medium CNN\", \"Large CNN\"]\n",
    "preds = [pred_small, pred_medium, pred_large]\n",
    "confs = [conf_small, conf_medium, conf_large]\n",
    "axs_titles = []\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(image.reshape(28, 28), cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"{models[i]}\\nPrédit : {preds[i]} | Vrai : {true_label}\\nConfiance : {confs[i]:.2f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
